{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56a97a76e5426a25af596845ad77537749987d41"
      },
      "cell_type": "code",
      "source": "# Import libraries and set desired options\n\n\n# Disable Anaconda warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport re\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\n\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Read the training and test data sets\ntrain_df = pd.read_csv('../input/train_sessions.csv',\n                       index_col='session_id')\ntest_df = pd.read_csv('../input/test_sessions.csv',\n                      index_col='session_id')\n\n# Switch time1, ..., time10 columns to datetime type\ntimes = ['time%s' % i for i in range(1, 11)]\ntrain_df[times] = train_df[times].apply(pd.to_datetime)\ntest_df[times] = test_df[times].apply(pd.to_datetime)\n\n# Sort the data by time\ntrain_df = train_df.sort_values(by='time1')\n\n# Look at the first rows of the training set\ntrain_df.head()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "            site1               time1  ...                time10 target\nsession_id                             ...                             \n21669          56 2013-01-12 08:05:57  ...                   NaT      0\n54843          56 2013-01-12 08:37:23  ...                   NaT      0\n77292         946 2013-01-12 08:50:13  ...   2013-01-12 08:50:17      0\n114021        945 2013-01-12 08:50:17  ...   2013-01-12 08:50:20      0\n146670        947 2013-01-12 08:50:20  ...   2013-01-12 08:50:22      0\n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>site1</th>\n      <th>time1</th>\n      <th>site2</th>\n      <th>time2</th>\n      <th>site3</th>\n      <th>time3</th>\n      <th>site4</th>\n      <th>time4</th>\n      <th>site5</th>\n      <th>time5</th>\n      <th>site6</th>\n      <th>time6</th>\n      <th>site7</th>\n      <th>time7</th>\n      <th>site8</th>\n      <th>time8</th>\n      <th>site9</th>\n      <th>time9</th>\n      <th>site10</th>\n      <th>time10</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>session_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21669</th>\n      <td>56</td>\n      <td>2013-01-12 08:05:57</td>\n      <td>55.0</td>\n      <td>2013-01-12 08:05:57</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54843</th>\n      <td>56</td>\n      <td>2013-01-12 08:37:23</td>\n      <td>55.0</td>\n      <td>2013-01-12 08:37:23</td>\n      <td>56.0</td>\n      <td>2013-01-12 09:07:07</td>\n      <td>55.0</td>\n      <td>2013-01-12 09:07:09</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>77292</th>\n      <td>946</td>\n      <td>2013-01-12 08:50:13</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:14</td>\n      <td>951.0</td>\n      <td>2013-01-12 08:50:15</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:15</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:16</td>\n      <td>945.0</td>\n      <td>2013-01-12 08:50:16</td>\n      <td>948.0</td>\n      <td>2013-01-12 08:50:16</td>\n      <td>784.0</td>\n      <td>2013-01-12 08:50:16</td>\n      <td>949.0</td>\n      <td>2013-01-12 08:50:17</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:17</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>114021</th>\n      <td>945</td>\n      <td>2013-01-12 08:50:17</td>\n      <td>948.0</td>\n      <td>2013-01-12 08:50:17</td>\n      <td>949.0</td>\n      <td>2013-01-12 08:50:18</td>\n      <td>948.0</td>\n      <td>2013-01-12 08:50:18</td>\n      <td>945.0</td>\n      <td>2013-01-12 08:50:18</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:18</td>\n      <td>947.0</td>\n      <td>2013-01-12 08:50:19</td>\n      <td>945.0</td>\n      <td>2013-01-12 08:50:19</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:19</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>146670</th>\n      <td>947</td>\n      <td>2013-01-12 08:50:20</td>\n      <td>950.0</td>\n      <td>2013-01-12 08:50:20</td>\n      <td>948.0</td>\n      <td>2013-01-12 08:50:20</td>\n      <td>947.0</td>\n      <td>2013-01-12 08:50:21</td>\n      <td>950.0</td>\n      <td>2013-01-12 08:50:21</td>\n      <td>952.0</td>\n      <td>2013-01-12 08:50:21</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:21</td>\n      <td>951.0</td>\n      <td>2013-01-12 08:50:22</td>\n      <td>946.0</td>\n      <td>2013-01-12 08:50:22</td>\n      <td>947.0</td>\n      <td>2013-01-12 08:50:22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sites = ['site%s' %i for i in range(1,11) ]\n\ntrain_df[sites] = train_df[sites].fillna(0).astype('int')\ntest_df[sites] = test_df[sites].fillna(0).astype('int')",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8c4c7b2a0252fde87737cd1e4ce360bb86686a1"
      },
      "cell_type": "code",
      "source": "# Load websites dictionary\nwith open(r\"../input/site_dic.pkl\", \"rb\") as input_file:\n    site_dict = pickle.load(input_file)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "d8c2f26494676c2a493f594c97222df770e42363"
      },
      "cell_type": "code",
      "source": "# Create dataframe for the dictionary\nsites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\nprint(u'Websites total:', sites_dict.shape[0])\n",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Websites total: 48371\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ff217dddbf714f1b3358633b7de4095f319d3ec"
      },
      "cell_type": "code",
      "source": "sites_dict=sites_dict.applymap(lambda site: re.sub(\"^\\S*?\\.*?www\\S*?\\.\", '', site))",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a028011ca8473cfddd5ddd684d62117f764aa0e3"
      },
      "cell_type": "code",
      "source": "full_df=pd.concat([train_df.drop('target',axis=1),test_df])",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7752257cf51694ea1fa10da2fa458a634faa80ff"
      },
      "cell_type": "code",
      "source": "full_df.shape",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "(336358, 20)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6bdabcaeaf4a48143d98f4677a1b3ed6c202486"
      },
      "cell_type": "code",
      "source": "idx_split=train_df.shape[0]",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e14c0a64726938cd1a8d3826f1536957254da81"
      },
      "cell_type": "code",
      "source": "# Our target variable\ny_train = train_df['target']\n",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6e663f8009f9e9cba4cdc5802a51c2f4db7878d"
      },
      "cell_type": "code",
      "source": "full_sites=full_df[sites]",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08799a1b71279629628e25e7df3872a09d5a5183"
      },
      "cell_type": "code",
      "source": "# sequence of indices\nsites_flatten = full_sites.values.flatten()\n\n# and the matrix we are looking for\nfull_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n                                sites_flatten,\n                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8888edf5e32baf59e3a7a8807efee8a0e39269c2"
      },
      "cell_type": "code",
      "source": "sites_flatten.shape",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "(3363580,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fcc615d4825ffe1da25805bf55c58ab3285e71c"
      },
      "cell_type": "code",
      "source": "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n    # Split the data into the training and validation sets\n    idx = int(round(X.shape[0] * ratio))\n    # Classifier training\n    lr = LogisticRegression(C=C, random_state=seed, n_jobs=-1).fit(X[:idx, :], y[:idx])\n    # Prediction for validation set\n    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n    # Calculate the quality\n    score = roc_auc_score(y[idx:], y_pred)\n    \n    return score",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "117e29ff66f581f91c047f591f71876360b6311a"
      },
      "cell_type": "code",
      "source": "%%time\n# Select the training set from the united dataframe (where we have the answers)\nX_train = full_sites_sparse[:idx_split, :]\n\n# Calculate metric on the validation set\nprint(get_auc_lr_valid(X_train, y_train))",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9195244077552184\nCPU times: user 4.44 s, sys: 0 ns, total: 4.44 s\nWall time: 4.44 s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "647957d84f4bc11fb74affccaf109a8c0c1e7b05"
      },
      "cell_type": "code",
      "source": "# Function for writing predictions to a file\ndef write_to_submission_file(predicted_labels, out_file,\n                             target='target', index_label=\"session_id\"):\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(1, predicted_labels.shape[0] + 1),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "423a832440a18aa78db11d6f16f0a6357544e7c6"
      },
      "cell_type": "code",
      "source": "# Train the model on the whole training data set\n# Use random_state=17 for repeatability\n# Parameter C=1 by default, but here we set it explicitly\nlr = LogisticRegression(C=1.0, random_state=17).fit(X_train, y_train)\n\n# Make a prediction for test data set\nX_test = full_sites_sparse[idx_split:,:]\ny_test = lr.predict_proba(X_test)[:, 1]\n\n# Write it to the file which could be submitted\nwrite_to_submission_file(y_test, 'baseline_1.csv')",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d931c1df43a0de2a0cdc895e1e927c8199703106"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a38c73c10237acd31ccfba1cc42782f0e8e2490e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85b24d7cefedcb56df42a0a3aaf27d4f0ad130ed"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}